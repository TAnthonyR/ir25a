{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "941741204a003f44",
      "metadata": {
        "id": "941741204a003f44"
      },
      "source": [
        "# Ejercicio 4: Modelo Probabilístico\n",
        "\n",
        "## Objetivo de la práctica\n",
        "- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n",
        "- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n",
        "- Comparar la recuperación con BM25 frente a TF-IDF.\n",
        "- Analizar visualmente las diferencias entre los modelos.\n",
        "- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93bafe7a6a4ef9e5",
      "metadata": {
        "id": "93bafe7a6a4ef9e5"
      },
      "source": [
        "## Parte 0: Carga del Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ad08bb8bd43ae327",
      "metadata": {
        "id": "ad08bb8bd43ae327"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "corpus = newsgroups.data\n",
        "target = newsgroups.target\n",
        "target_names = newsgroups.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KB3fS0sWtXw6",
      "metadata": {
        "id": "KB3fS0sWtXw6"
      },
      "source": [
        "## Normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "yEKjD3MytckD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEKjD3MytckD",
        "outputId": "c2c96430-e0d2-41e3-cb54-15732885e875"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab') # para tokenizar el texto en palabras.\n",
        "nltk.download('stopwords') # para eliminar palabras vacías como “the”, “and”, “is”, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "mQn5SCTTtlCF",
      "metadata": {
        "id": "mQn5SCTTtlCF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def normalizar(texto):\n",
        "    texto = texto.lower()  # minúsculas\n",
        "    texto = re.sub(r'\\d+', '', texto)  # eliminar números\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)  # eliminar puntuación\n",
        "    tokens = word_tokenize(texto)\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Aplicar al corpus\n",
        "corpus_n = [normalizar(doc) for doc in corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f8c7f78934f497",
      "metadata": {
        "id": "10f8c7f78934f497"
      },
      "source": [
        "## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n",
        "\n",
        "### Actividad\n",
        "1. Utiliza el corpus cargado.\n",
        "2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n",
        "3. Calcula TF-IDF utilizando sklearn.\n",
        "4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d2ebd9f1c1b6c787",
      "metadata": {
        "id": "d2ebd9f1c1b6c787"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oJvwqBMx0-ZI",
      "metadata": {
        "id": "oJvwqBMx0-ZI"
      },
      "source": [
        "### Matriz TF, y cálculo de la frecuencia de documentos DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "x_NZ56bW1HBQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_NZ56bW1HBQ",
        "outputId": "a422a267-4e6d-4811-8174-3c793d1bc6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape de la matriz de términos: (18846, 122066)\n",
            "       ___  ____  _____  ______  _______  ________  _________  __________  \\\n",
            "0        0     0      0       0        0         0          0           0   \n",
            "1        0     0      0       0        0         0          0           0   \n",
            "2        0     0      0       0        0         0          0           0   \n",
            "3        0     0      0       0        0         0          0           0   \n",
            "4        0     0      0       0        0         0          0           0   \n",
            "...    ...   ...    ...     ...      ...       ...        ...         ...   \n",
            "18841    0     0      0       0        0         0          0           0   \n",
            "18842    0     0      0       0        0         0          0           0   \n",
            "18843    0     0      0       0        0         0          0           0   \n",
            "18844    0     0      0       0        0         0          0           0   \n",
            "18845    0     0      0       0        0         0          0           0   \n",
            "\n",
            "       ___________  ____________  ...  zyxelb  zzc  zzip  zztvtznth  \\\n",
            "0                0             0  ...       0    0     0          0   \n",
            "1                0             0  ...       0    0     0          0   \n",
            "2                0             0  ...       0    0     0          0   \n",
            "3                0             0  ...       0    0     0          0   \n",
            "4                0             0  ...       0    0     0          0   \n",
            "...            ...           ...  ...     ...  ...   ...        ...   \n",
            "18841            0             0  ...       0    0     0          0   \n",
            "18842            0             0  ...       0    0     0          0   \n",
            "18843            0             0  ...       0    0     0          0   \n",
            "18844            0             0  ...       0    0     0          0   \n",
            "18845            0             0  ...       0    0     0          0   \n",
            "\n",
            "       zzyhcnafb_o  zzzs  zzzzzz  zzzzzzt  µsec  ÿhooked  \n",
            "0                0     0       0        0     0        0  \n",
            "1                0     0       0        0     0        0  \n",
            "2                0     0       0        0     0        0  \n",
            "3                0     0       0        0     0        0  \n",
            "4                0     0       0        0     0        0  \n",
            "...            ...   ...     ...      ...   ...      ...  \n",
            "18841            0     0       0        0     0        0  \n",
            "18842            0     0       0        0     0        0  \n",
            "18843            0     0       0        0     0        0  \n",
            "18844            0     0       0        0     0        0  \n",
            "18845            0     0       0        0     0        0  \n",
            "\n",
            "[18846 rows x 122066 columns]\n"
          ]
        }
      ],
      "source": [
        "# Crear matriz de frecuencia de términos\n",
        "count_vect = CountVectorizer()\n",
        "X_counts = count_vect.fit_transform(corpus_n)\n",
        "print(f\"Shape de la matriz de términos: {X_counts.shape}\")\n",
        "\n",
        "# Obtener nombres de términos\n",
        "terms = count_vect.get_feature_names_out()\n",
        "\n",
        "# Convertir a DataFrame (TF)\n",
        "tf= pd.DataFrame(X_counts.toarray(), columns=terms)\n",
        "print(tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "Xwd-5PHi6Oh8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwd-5PHi6Oh8",
        "outputId": "e72b2de4-0342-48b9-da00-29303cffe18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           term  df\n",
            "0           ___  67\n",
            "1          ____  48\n",
            "2         _____  42\n",
            "3        ______  26\n",
            "4       _______  35\n",
            "...         ...  ..\n",
            "122061     zzzs   1\n",
            "122062   zzzzzz   1\n",
            "122063  zzzzzzt   1\n",
            "122064     µsec   1\n",
            "122065  ÿhooked   1\n",
            "\n",
            "[122066 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Calcular DF (cuántos documentos contienen cada término)\n",
        "df_series = (X_counts > 0).sum(axis=0).A1  # A1 convierte a arreglo plano\n",
        "df= pd.DataFrame({'term': terms, 'df': df_series})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q9Q0sSYFx8gi",
      "metadata": {
        "id": "Q9Q0sSYFx8gi"
      },
      "source": [
        "### Calcular TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "dW-JHTWtv1RY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW-JHTWtv1RY",
        "outputId": "707fbd46-abea-459c-fe6b-5252663df6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape del TF-IDF matrix: (18846, 122066)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "corpus_vect = vectorizer.fit_transform(corpus_n)\n",
        "print(f\"Shape del TF-IDF matrix: {corpus_vect.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "Wy_63iw3wdGd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy_63iw3wdGd",
        "outputId": "ee745053-6a9c-4f6d-8b90-c743a48b9de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       ___  ____  _____  ______  _______  ________  _________  __________  \\\n",
            "0      0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "1      0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "2      0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "3      0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "4      0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "...    ...   ...    ...     ...      ...       ...        ...         ...   \n",
            "18841  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "18842  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "18843  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "18844  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "18845  0.0   0.0    0.0     0.0      0.0       0.0        0.0         0.0   \n",
            "\n",
            "       ___________  ____________  ...  zyxelb  zzc  zzip  zztvtznth  \\\n",
            "0              0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "1              0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "2              0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "3              0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "4              0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "...            ...           ...  ...     ...  ...   ...        ...   \n",
            "18841          0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "18842          0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "18843          0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "18844          0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "18845          0.0           0.0  ...     0.0  0.0   0.0        0.0   \n",
            "\n",
            "       zzyhcnafb_o  zzzs  zzzzzz  zzzzzzt  µsec  ÿhooked  \n",
            "0              0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "1              0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "2              0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "3              0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "4              0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "...            ...   ...     ...      ...   ...      ...  \n",
            "18841          0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "18842          0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "18843          0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "18844          0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "18845          0.0   0.0     0.0      0.0   0.0      0.0  \n",
            "\n",
            "[18846 rows x 122066 columns]\n"
          ]
        }
      ],
      "source": [
        "terms = vectorizer.get_feature_names_out()\n",
        "tfidf = pd.DataFrame(corpus_vect.toarray(), columns=terms)\n",
        "print(tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WVwdbmrSyrJU",
      "metadata": {
        "id": "WVwdbmrSyrJU"
      },
      "source": [
        "### Visualizar y analizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "AfsgNsJvx_uP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfsgNsJvx_uP",
        "outputId": "e669ee61-9b0b-4e67-909e-799fc8c82cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 términos por DF:\n",
            "          term    df\n",
            "118309   would  5259\n",
            "80782      one  5109\n",
            "52704     like  4166\n",
            "26551     dont  3889\n",
            "50176     know  3784\n",
            "36854      get  3625\n",
            "3902      also  3229\n",
            "108136   think  3127\n",
            "84169   people  2941\n",
            "108733    time  2848\n"
          ]
        }
      ],
      "source": [
        "top_df = df.sort_values(by='df', ascending=False).head(10)\n",
        "print(\"Top 10 términos por DF:\")\n",
        "print(top_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "M5zbXJgPyYla",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5zbXJgPyYla",
        "outputId": "50e09192-8ccb-481e-87c9-6f50f340292b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF del documento 0:\n",
            "pens                0.548236\n",
            "jagr                0.250831\n",
            "devils              0.216622\n",
            "bit                 0.193723\n",
            "fun                 0.185855\n",
            "regular             0.179938\n",
            "season              0.173826\n",
            "nonpittsburghers    0.169476\n",
            "bashers             0.151134\n",
            "pulp                0.151134\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"TF-IDF del documento 0:\")\n",
        "print(tfidf.iloc[0].sort_values(ascending=False).head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64491bce5361e8b3",
      "metadata": {
        "id": "64491bce5361e8b3"
      },
      "source": [
        "## Parte 2: Ranking de documentos usando TF-IDF\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Dada una consulta, construye el vector de consulta\n",
        "2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n",
        "3. Genera un ranking de los documentos ordenados por relevancia.\n",
        "4. Muestra los resultados en una tabla."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "va6BEzxN7lPE",
      "metadata": {
        "id": "va6BEzxN7lPE"
      },
      "source": [
        "## Crear el vector consulta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "lzHrmVuj7pN9",
      "metadata": {
        "id": "lzHrmVuj7pN9"
      },
      "outputs": [],
      "source": [
        "query = \"jersey\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "rjv_3E407vLb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjv_3E407vLb",
        "outputId": "e012573c-7582-4e08-f0bb-e65f619683db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 1 stored elements and shape (1, 122066)>\n",
            "  Coords\tValues\n",
            "  (0, 105455)\t1.0\n"
          ]
        }
      ],
      "source": [
        "query_vect = vectorizer.transform([query])\n",
        "print(query_vect)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fHCnc0oW76b9",
      "metadata": {
        "id": "fHCnc0oW76b9"
      },
      "source": [
        "### Calcular la similitud coseno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "I3izZxqt7-wW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3izZxqt7-wW",
        "outputId": "d09eea60-72b1-458c-dfbf-da27d6648178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.05957388 0.         0.         ... 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "dist = cosine_similarity(query_vect, corpus_vect).flatten() # dist arreglo de similitudes de la consulta y cada documento entre [0-1]\n",
        "print(dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vL0tn_t28xI0",
      "metadata": {
        "id": "vL0tn_t28xI0"
      },
      "source": [
        "### Generar el ranking y mostrar tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "8C6MdN2K8vtj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8C6MdN2K8vtj",
        "outputId": "62f01f7b-38e7-47e8-aeab-078e7eb8b546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Ranking                                    Documento  Similitud coseno\n",
            "0         1                            yes quite sure...          0.532558\n",
            "1         2               might sure would also wrong...          0.484247\n",
            "2         3  sure exact recipe sure acidophilus one m...          0.396370\n",
            "3         4              sure wouldnt wasnt advantage...          0.381522\n",
            "4         5                       sure ill give bucks...          0.375741\n",
            "5         6  consider action still sure know trying s...          0.348511\n",
            "6         7  could someone explain names come sure th...          0.324277\n",
            "7         8  dominik tried xgrasp several ftp sitesno...          0.299423\n",
            "8         9  well depends motherboard implimentation ...          0.282344\n",
            "9        10  think another formula era heard somethin...          0.274262\n",
            "10       11  sure two visitors really government agen...          0.266224\n",
            "11       12  sure youre running enhanced mode windows...          0.265152\n",
            "12       13  sure dont know bike worked sure wasnt vi...          0.249100\n",
            "13       14  reply tgkcstorontoedu todd kelley agreed...          0.245443\n",
            "14       15  take moment digest sure youll see humour...          0.240846\n",
            "15       16  well dont normally like quote got additi...          0.239879\n",
            "16       17  moved alabama california sympathies make...          0.239481\n",
            "17       18  careful plug external monitor external s...          0.239382\n",
            "18       19  assuming families inner city dont family...          0.231547\n",
            "19       20  seen various references triple des recen...          0.229168\n",
            "20       21  appreciate support statement sure really...          0.222393\n",
            "21       22  tell sure three days havent passed yet s...          0.219680\n",
            "22       23  yes equipment telekom approval number le...          0.216907\n",
            "23       24  made mind waco sure seems group devoted ...          0.214671\n",
            "24       25  sure whole newspaper copyrighted could g...          0.213235\n",
            "25       26  could someone explain names come sure th...          0.209505\n",
            "26       27  hey get together one poor college studen...          0.208998\n",
            "27       28  make sure hard disk want boot set active...          0.208298\n",
            "28       29  well seemed work mac installation talkin...          0.206172\n",
            "29       30  great nice choice bad guys convince ever...          0.203372\n",
            "30       31  hmm turks sure know keep track deaths se...          0.203310\n",
            "31       32  anyone doesnt agree definitions useless ...          0.202196\n",
            "32       33  change login passwords every couple mont...          0.201996\n",
            "33       34  check vopl vogle libraries beleive still...          0.201915\n",
            "34       35  useful info maxtor drive deleted however...          0.199485\n",
            "35       36  chop could please post net please sure m...          0.199014\n",
            "36       37  sure sorry rechumor try cica pubpcwin ge...          0.197610\n",
            "37       38  yes dont know douglas adams took pretty ...          0.194941\n",
            "38       39  eggertjmaymosesllmitedu eggertjmosesllmi...          0.193802\n",
            "39       40  knx unhappy hear sure isnt knbr bay area...          0.193654\n",
            "40       41  live british columbia canadathe cable co...          0.193009\n",
            "41       42  yeah make darn sure cover glass driver c...          0.191767\n",
            "42       43  bill james yeah sure bill james players ...          0.189836\n",
            "43       44  another tip make sure keep well one side...          0.189802\n",
            "44       45  nice cop bill sure youre right idea refe...          0.189047\n",
            "45       46  make sure take sutcliff fisk ect factor ...          0.186794\n",
            "46       47  backdeskzip cica sure whole directory an...          0.185915\n",
            "47       48  vouch method sho sure way putting revers...          0.185432\n",
            "48       49  perhaps responding yankees part comment ...          0.184834\n",
            "49       50  much deleted brevity certainly smacks re...          0.183783\n"
          ]
        }
      ],
      "source": [
        "top_k = 50\n",
        "\n",
        "# Ranking de indices debe ser una lista de enteros\n",
        "ranking_indices = dist.argsort()[::-1] # argsort devuelve índices de menor a mayor y con [::1] invertimos ese orden\n",
        "\n",
        "# Construcción del DataFrame\n",
        "resultados = pd.DataFrame({\n",
        "    'Ranking': range(1, top_k + 1),\n",
        "    'Documento': [corpus_n[i][:40].replace('\\n', ' ') + '...' for i in ranking_indices[:top_k]],\n",
        "    'Similitud coseno': [dist[i] for i in ranking_indices[:top_k]],\n",
        "    #'Categoría': [target_names[target[i]] for i in ranking_indices[:top_k]] #\n",
        "})\n",
        "\n",
        "print(resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97061325508dc5f2",
      "metadata": {
        "id": "97061325508dc5f2"
      },
      "source": [
        "## Parte 3: Ranking con BM25\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Implementa un sistema de recuperación usando el modelo BM25.\n",
        "2. Usa la misma consulta del ejercicio anterior.\n",
        "3. Calcula el score BM25 para cada documento y genera un ranking.\n",
        "4. Compara manualmente con el ranking de TF-IDF."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c71b85e77b4b181",
      "metadata": {
        "id": "2c71b85e77b4b181"
      },
      "source": [
        "## Parte 4: Comparación visual entre TF-IDF y BM25\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Utiliza un gráfico de barras para visualizar los scores obtenidos por cada documento según TF-IDF y BM25.\n",
        "2. Compara los rankings visualmente.\n",
        "3. Identifica: ¿Qué documentos obtienen scores más altos en un modelo que en otro?\n",
        "4. Sugiere: ¿A qué se podría deber esta diferencia?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b97d171655ecfb",
      "metadata": {
        "id": "b97d171655ecfb"
      },
      "source": [
        "## Parte 5: Evaluación con consulta relevante\n",
        "\n",
        "### Actividad\n",
        "\n",
        "1. Elige una consulta y define qué documentos del corpus deberían considerarse relevantes.\n",
        "2. Evalúa Precision@3 o MAP para los rankings generados con TF-IDF y BM25.\n",
        "3. Responde: ¿Cuál modelo da mejores resultados respecto a tu criterio de relevancia?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
